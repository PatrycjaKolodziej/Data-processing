{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJN1YrENU4+kgHcGMf6OYa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Co to jest serializacja i dlaczego powinno nas to obchodzić?\n",
        "# Pomyśl o przechowywaniu liczby całkowitej; jak chcesz to zapisać w pliku lub przesłać? To łatwe! \n",
        "# Możemy po prostu zapisać liczbę całkowitą do pliku i zapisać lub przesłać ten plik.\n",
        "\n",
        "# Ale co, jeśli pomyślimy o przechowywaniu obiektu Pythona (np. słownika Pythona lub Pandas DataFrame), \n",
        "# który ma złożoną strukturę i wiele atrybutów (np. kolumny i indeks DataFrame oraz typ danych każdej kolumny )? \n",
        "# W jaki sposób zapiszesz go jako plik lub prześlesz na inny komputer?\n",
        "\n",
        "# Tu właśnie pojawia się serializacja!\n",
        "\n",
        "# Serializacja to proces konwersji obiektu do formatu, który można przechowywać lub przesyłać.\n",
        "# Po przesłaniu lub zapisaniu serializowanych danych jesteśmy w stanie później zrekonstruować obiekt i\n",
        "# uzyskać dokładnie taką samą strukturę/obiekt, co sprawia, że ​​naprawdę wygodnie jest nam później korzystać z przechowywanego\n",
        "# obiektu zamiast rekonstruować obiekt od podstaw.\n",
        "\n",
        "# W Pythonie dostępnych jest wiele różnych formatów serializacji. Typowym przykładem map skrótów (słowników Pythona), które działają w wielu językach, jest format pliku JSON, który jest czytelny dla człowieka i pozwala nam przechowywać słownik i odtwarzać go z tą samą strukturą. Ale JSON może przechowywać tylko podstawowe struktury, takie jak lista i słownik, \n",
        "# i może przechowywać tylko ciągi znaków i liczby. Nie możemy poprosić JSON o zapamiętanie typu danych\n",
        "# (np. numpy float32 vs. float64). Nie można również odróżnić krotek Pythona od list.\n",
        "\n",
        "# Istnieją potężniejsze formaty serializacji. Poniżej przyjrzymy się dwóm popularnym bibliotekom serializacji w Pythonie, a mianowicie pickle i h5py."
      ],
      "metadata": {
        "id": "HzNL6xM8Pc-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OslaLcojDOyl",
        "outputId": "873d1e2f-bd2a-49a0-be3a-b9089d030071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp39-cp39-linux_x86_64.whl size=255889 sha256=fd588337d6dbd236abf7e02d2b2ca144770140792141779ab7a912a526dc5ff4\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/7a/49/9bef8878949914ecb90c08fc5bf30a05e17f475fe7e08b63a8\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ]
        }
      ],
      "source": [
        "!pip install pickle5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "xnkkmh4fDco3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## tworzymy słownik i zapisujmy go"
      ],
      "metadata": {
        "id": "QA9mCeM9PoxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict = {\"Hello\" : \"World!\"}"
      ],
      "metadata": {
        "id": "EnudyPYNDgsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DXUxXOAP5qw",
        "outputId": "72755262-c154-4721-be66-5068da22ba9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict = {\"Hello\": \"World!\"}\n",
        "with open(\"test.pickle\", \"wb\") as outfile:\n",
        " \t# \"wb\" argument opens the file in binary mode\n",
        "\tpickle.dump(test_dict, outfile)"
      ],
      "metadata": {
        "id": "QZEiIIVDDu6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## wczytujemy go spowrotem"
      ],
      "metadata": {
        "id": "hNEMAXaNQAN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"test.pickle\", \"rb\") as infile:\n",
        "      test_dict_reconstructed = pickle.load(infile)"
      ],
      "metadata": {
        "id": "5NurgDTrQA50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict_reconstructed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsERsXpMQGLY",
        "outputId": "5eac57d5-3e9d-4ba0-d70f-107a99f21511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Hello': 'World!'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict_ba = pickle.dumps(test_dict)"
      ],
      "metadata": {
        "id": "JpDVKaqPQJQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict_ba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bku5fJxQMKc",
        "outputId": "a06c7d54-73c5-4280-c0a5-bb5e988b4241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'\\x80\\x04\\x95\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x94\\x8c\\x05Hello\\x94\\x8c\\x06World!\\x94s.'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## zapisujemy modele"
      ],
      "metadata": {
        "id": "XqGwBOt-QPLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## można odpalić jeżeli zainstalujecie tensorflowa"
      ],
      "metadata": {
        "id": "fi7eOBmQQSlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, AveragePooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        " \n",
        "# Load MNIST digits\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        " \n",
        "# Reshape data to (n_samples, height, wiedth, n_channel)\n",
        "X_train = np.expand_dims(X_train, axis=3).astype(\"float32\")\n",
        "X_test = np.expand_dims(X_test, axis=3).astype(\"float32\")\n",
        " \n",
        "# One-hot encode the output\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        " \n",
        "# LeNet5 model\n",
        "model = Sequential([\n",
        "    Conv2D(6, (5,5), input_shape=(28,28,1), padding=\"same\", activation=\"tanh\"),\n",
        "    AveragePooling2D((2,2), strides=2),\n",
        "    Conv2D(16, (5,5), activation=\"tanh\"),\n",
        "    AveragePooling2D((2,2), strides=2),\n",
        "    Conv2D(120, (5,5), activation=\"tanh\"),\n",
        "    Flatten(),\n",
        "    Dense(84, activation=\"tanh\"),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        " \n",
        "# Train the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "earlystopping = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=[earlystopping])\n",
        " \n",
        "# Evaluate the model\n",
        "print(model.evaluate(X_test, y_test, verbose=0))\n",
        " \n",
        "# Pickle to serialize and deserialize\n",
        "pickled_model = pickle.dumps(model)\n",
        "reconstructed = pickle.loads(pickled_model)\n",
        " \n",
        "# Evaluate again\n",
        "print(reconstructed.evaluate(X_test, y_test, verbose=0))"
      ],
      "metadata": {
        "id": "cteM2EUfD5Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "# Generate the Profiling Report\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4bU2fo7HHqa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic"
      ],
      "metadata": {
        "id": "qhWB3rb2H0oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile = ProfileReport(titianic_df,\n",
        "                         title=\"Titanic Dataset\",\n",
        "                         html={'style': {'full_width': True}},\n",
        "                         sort=None)\n",
        "                        # Save to file\n",
        "profile.to_file('report.html')"
      ],
      "metadata": {
        "id": "c0onEO0cGoTu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}